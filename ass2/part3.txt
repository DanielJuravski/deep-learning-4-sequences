POS best parameters:
Hidden layer size =
Optimizer =
Learning Rate =
(?)Regularization =
Epochs =

NER best parameters:
Hidden layer size =
Optimizer =
Learning Rate =
(?)Regularization =
Epochs =

Considerations:
- There were words that appear in the training file but not the embeddings file, we treated them in a similar way like in part 1.
by adding four different vectors to unknown words and mapping to the correct unknown vector by the word's features

- The embedding vocabulary represented all with lower-case. So appropriately we searched for the lower cased representation
of the word, if it was not found than we mapped it to the correct unknown word vector
- Did accuracy improve over the tagger without the pre-trained embeddings? by how much?